{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import namedtuple\n",
    "\n",
    "m_acc = namedtuple('ModelAccuracy', 'loss loss_fn opt model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.Tensor([[0,0],[0,1],[1,0],[1,1]])\n",
    "y = torch.Tensor([1,0,0,1]).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Sequential(\n",
    "    *[\n",
    "        nn.Linear(2, 10),\n",
    "        nn.Sigmoid(),\n",
    "        nn.Linear(10, 1),\n",
    "        nn.Sigmoid(),\n",
    "    ]\n",
    ")\n",
    "inp = torch.Tensor([0, 0])\n",
    "print(m.forward(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, model, loss_fn, optimizer, epochs):\n",
    "    losses = []\n",
    "    for epoch in range(epochs):\n",
    "        y_pred = model(X)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        losses.append(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return m_acc(loss=losses,loss_fn=loss_fn, opt=optimizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No batches\n",
    "loss_fns = [getattr(nn,loss) for loss in dir(nn) if loss.endswith(\"Loss\")]\n",
    "opt_fns = [getattr(torch.optim, opt) for opt in dir(torch.optim) if isinstance(getattr(torch.optim, opt),type)]\n",
    "\n",
    "models = []\n",
    "count = 0\n",
    "for loss_fn in loss_fns:\n",
    "    for opt_fn in opt_fns:\n",
    "        try:\n",
    "            curr_loss_fn = loss_fn()\n",
    "            curr_opt_fn = opt_fn(m.parameters())\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to create {loss_fn} and {opt_fn} Error:\",e)\n",
    "            continue\n",
    "        try:\n",
    "            ret = train(X, y, m,curr_loss_fn,curr_opt_fn, 1000)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to train {loss_fn} and {opt_fn} Error:\",e)\n",
    "            continue\n",
    "        \n",
    "        models.append(ret)\n",
    "\n",
    "print(len(models))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = sorted(models, key=lambda x: x.loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "for tup in models:\n",
    "    torch.save(tup.model.state_dict(), f\"first_models/{tup.loss_fn.__class__.__name__}----{tup.opt.__class__.__name__}.pt\")\n",
    "print(len(models))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "fin = []\n",
    "for m in models:\n",
    "    for i in range(len(m.loss)):\n",
    "        fin.append((i,m.loss[i]*1000, m.opt.__class__.__name__+\"__\"+m.loss_fn.__class__.__name__))\n",
    "    \n",
    "df = pd.DataFrame(fin, columns=[\"epoch\", \"loss\", \"opt_loss\"])\n",
    "    \n",
    "line = px.scatter(df,x=\"epoch\", y=\"loss\", color=\"opt_loss\")\n",
    "\n",
    "line.write_html(\"data_compare.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f2a368c517cb59615749bce5fd61baff4e9b71fee3f5905eb4825d6407987573"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
